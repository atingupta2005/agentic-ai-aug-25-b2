{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ce72ca-8569-4640-ae0d-c7ef687fe278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ac9a9b60484e9ca9accf330666ab4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n",
      "C:\\Users\\adminuser\\AppData\\Local\\Temp\\ipykernel_6236\\3134622074.py:20: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'validators'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  response: str = Field(\n"
     ]
    }
   ],
   "source": [
    "import guardrails as gd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import ClassVar, Dict, Any\n",
    "from guardrails.hub import GuardrailsPII \n",
    "import json # Keep this import, we will use it explicitly for dumps\n",
    "\n",
    "# --- 1. Define the Structured Output with PII Protection ---\n",
    "\n",
    "class LLMAnswer(BaseModel):\n",
    "    \"\"\"\n",
    "    Pydantic Model defining the LLM's expected output structure.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define pii_validator as a ClassVar to prevent Pydantic from treating it as a data field.\n",
    "    pii_validator: ClassVar[GuardrailsPII] = GuardrailsPII(\n",
    "        entities=[\"EMAIL_ADDRESS\", \"PHONE_NUMBER\", \"US_SSN\"], \n",
    "        on_fail=\"fix\" \n",
    "    )\n",
    "\n",
    "    response: str = Field(\n",
    "        description=\"The LLM's full answer to the question.\",\n",
    "        validators=[pii_validator]\n",
    "    )\n",
    "    \n",
    "    context_source: str = Field(\n",
    "        description=\"The source document or context used for the answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- 2. Simulate the LLM's Behavior (Raw Output) ---\n",
    "\n",
    "def generate_unsafe_llm_response() -> str:\n",
    "    \"\"\"\n",
    "    Simulates a Large Language Model returning raw JSON output that includes PII.\n",
    "    \"\"\"\n",
    "    raw_response_data = {\n",
    "        \"response\": \"The new policy details were sent to John Doe at john.doe@secure-corp.net. His mobile number is 555-867-5309. This information is confidential.\",\n",
    "        \"context_source\": \"Policy Manual V1.2\"\n",
    "    }\n",
    "    return json.dumps(raw_response_data)\n",
    "\n",
    "\n",
    "# --- 3. Execute the Guarded Flow (FIXED) ---\n",
    "\n",
    "def run_pii_redaction_test():\n",
    "    \"\"\"\n",
    "    Initializes the Guard from the Pydantic model and runs the test, \n",
    "    using modern Pydantic V2 methods.\n",
    "    \"\"\"\n",
    "    n\n",
    "    guard = gd.Guard.from_pydantic(output_class=LLMAnswer)\n",
    "    raw_llm_output = generate_unsafe_llm_response()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"üî¥ RAW LLM OUTPUT (Contains PII)\")\n",
    "    print(\"=\"*80)\n",
    "    print(raw_llm_output)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üü° GUARDRAIL PARSING & REDACTION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # 1. Get the ValidationOutcome object. PII detection and redaction happens here.\n",
    "        outcome = guard.parse(llm_output=raw_llm_output)\n",
    "\n",
    "        # 2. Get the validated output, which is a Python dictionary after fixing.\n",
    "        validated_output_data: Dict[str, Any] = outcome.validated_output\n",
    "\n",
    "        # 3. Convert the dictionary back to a JSON string.\n",
    "        #    This is safe and avoids the internal Guardrails issue.\n",
    "        validated_json_string = json.dumps(validated_output_data)\n",
    "        \n",
    "        # 4. ‚úÖ Pydantic V2 FIX: Use model_validate_json instead of parse_raw\n",
    "        final_output = LLMAnswer.model_validate_json(validated_json_string)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ GUARDED FINAL OUTPUT (PII Redacted)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # 5. ‚úÖ Pydantic V2 FIX: Use model_dump_json instead of json()\n",
    "        #    Use indent=4 to format the output nicely.\n",
    "        print(final_output.model_dump_json(indent=4))\n",
    "    \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during guardrail processing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c9f701-870e-498f-88e2-6900694864ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv311\\Lib\\site-packages\\guardrails\\validator_service\\__init__.py:84: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üî¥ RAW LLM OUTPUT (Contains PII)\n",
      "================================================================================\n",
      "{\"response\": \"The new policy details were sent to John Doe at john.doe@secure-corp.net. His mobile number is 555-867-5309. This information is confidential.\", \"context_source\": \"Policy Manual V1.2\"}\n",
      "\n",
      "================================================================================\n",
      "üü° GUARDRAIL PARSING & REDACTION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚úÖ GUARDED FINAL OUTPUT (PII Redacted)\n",
      "================================================================================\n",
      "{\n",
      "    \"response\": \"The new policy details were sent to John Doe at <EMAIL_ADDRESS>. His mobile number is <PHONE_NUMBER>. This information is confidential.\",\n",
      "    \"context_source\": \"Policy Manual V1.2\"\n",
      "}\n",
      "\n",
      "--- PII Summary ---\n",
      "Original Email: john.doe@secure-corp.net  -> Redacted to [EMAIL_ADDRESS]\n",
      "Original Phone: 555-867-5309             -> Redacted to [PHONE_NUMBER]\n"
     ]
    }
   ],
   "source": [
    "run_pii_redaction_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa257e6-484f-4f4d-8810-c636d0e391b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv311\\Lib\\site-packages\\guardrails\\validator_service\\__init__.py:84: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üî¥ RAW LLM OUTPUT (Contains PII)\n",
      "================================================================================\n",
      "{\"response\": \"The new policy details were sent to John Doe at john.doe@secure-corp.net. His mobile number is 555-867-5309. This information is confidential.\", \"context_source\": \"Policy Manual V1.2\"}\n",
      "\n",
      "================================================================================\n",
      "‚úÖ GUARDED FINAL OUTPUT (PII Redacted)\n",
      "================================================================================\n",
      "An error occurred during guardrail processing: 1 validation error for LLMAnswer\n",
      "__root__\n",
      "  the JSON object must be str, bytes or bytearray, not ValidationOutcome [type=type_error, input_value=ValidationOutcome(call_id...passed=True, error=None), input_type=ValidationOutcome]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adminuser\\AppData\\Local\\Temp\\ipykernel_1224\\1345588614.py:72: PydanticDeprecatedSince20: The `parse_raw` method is deprecated; if your data is JSON use `model_validate_json`, otherwise load the data then use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  final_output = LLMAnswer.parse_raw(validated_output_json_string)\n"
     ]
    }
   ],
   "source": [
    "run_pii_redaction_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16d71d29-0945-4247-bec1-46f0e61a5a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FailResult(outcome='fail', error_message='Output contains banned words', fix_value='a', error_spans=[ErrorSpan(start=1, end=6, reason=\"Found match with banned word 'athena' in 'thena'\")], metadata=None, validated_chunk=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ban_validator.validate(\"athena\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91797bc7-997a-4b41-add8-b41f24614c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FailResult(outcome='fail', error_message='Output contains banned words', fix_value='a', error_spans=[ErrorSpan(start=1, end=6, reason=\"Found match with banned word 'athena' in 'thena'\")], metadata=None, validated_chunk=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ban_validator.validate(\"athena\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660d5358-b4bb-41c5-9200-f7d06e53d6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed347f5a5ce4002aedd03d36513d0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n",
      "C:\\Users\\adminuser\\AppData\\Local\\Temp\\ipykernel_12560\\3095178899.py:29: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'validators'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  response: str = Field(\n"
     ]
    }
   ],
   "source": [
    "import guardrails as gd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import ClassVar, Dict, Any\n",
    "import json\n",
    "from guardrails.hub import GuardrailsPII \n",
    "from guardrails.hub import BanList \n",
    "# ‚úÖ FINAL FIX: Import GuardrailsError directly from the top-level 'guardrails' package\n",
    "# If this fails, the except block will still catch the base Exception.\n",
    "try:\n",
    "    from guardrails.errors import GuardrailsError\n",
    "except ImportError:\n",
    "    # Fallback to catching the base Python Exception if the library hides its own error class\n",
    "    GuardrailsError = Exception\n",
    "\n",
    "# --- 1. Define Output Guardrail (PII Redaction) ---\n",
    "\n",
    "class LLMAnswer(BaseModel):\n",
    "    \"\"\"\n",
    "    Pydantic Model for the safe, structured LLM output.\n",
    "    \"\"\"\n",
    "    \n",
    "    # OUTPUT VALIDATOR (GuardrailsPII)\n",
    "    pii_validator: ClassVar[GuardrailsPII] = GuardrailsPII(\n",
    "        entities=[\"EMAIL_ADDRESS\", \"PHONE_NUMBER\", \"US_SSN\"], \n",
    "        # Action: Automatically redact PII\n",
    "        on_fail=\"fix\" \n",
    "    )\n",
    "\n",
    "    response: str = Field(\n",
    "        description=\"The LLM's full answer to the question.\",\n",
    "        validators=[pii_validator]\n",
    "    )\n",
    "    \n",
    "    context_source: str = Field(\n",
    "        description=\"The source document or context used for the answer.\"\n",
    "    )\n",
    "\n",
    "# --- 2. Define Input Guardrail (BanList for Sensitive Terms) ---\n",
    "\n",
    "SENSITIVE_TERMS = [\"Atin\", \"codename\", \"project-x\", \"athena\", \"launch-date\"]\n",
    "\n",
    "# The BanList validator is configured to raise an exception if a banned word is found.\n",
    "input_ban_validator = BanList(\n",
    "    banned_words=SENSITIVE_TERMS,\n",
    "    on_fail=\"exception\" \n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. Simulate the LLM's Behavior (for Output Guardrail Test) ---\n",
    "\n",
    "def generate_unsafe_llm_response() -> str:\n",
    "    \"\"\"\n",
    "    Simulates a RAW response containing PII.\n",
    "    \"\"\"\n",
    "    raw_response_data = {\n",
    "        \"response\": \"The new policy details were sent to John Doe at john.doe@secure-corp.net. His mobile number is 555-867-5309. This information is confidential.\",\n",
    "        \"context_source\": \"Policy Manual V1.2\"\n",
    "    }\n",
    "    return json.dumps(raw_response_data)\n",
    "\n",
    "\n",
    "# --- 4. Execute the Full Guarded Flow ---\n",
    "\n",
    "def run_guarded_flow(user_prompt: str, raw_llm_output: str):\n",
    "    \"\"\"\n",
    "    Runs the full flow: Input Check -> Output Fix.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"User Prompt Received: {user_prompt}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # --- INPUT GUARDRAIL CHECK (BanList) ---\n",
    "    try:\n",
    "        print(\"üü° STEP 1: Applying Input Guardrail (BanList)...\")\n",
    "\n",
    "        SENSITIVE_TERMS = [\"Atin\", \"codename\", \"project-x\", \"athena\", \"launch-date\"]\n",
    "\n",
    "        # The BanList validator is configured to raise an exception if a banned word is found.\n",
    "        input_ban_validator = BanList(\n",
    "            banned_words=SENSITIVE_TERMS,\n",
    "            on_fail=\"exception\" \n",
    "        )\n",
    "\n",
    "        # We use the validator's validate() method directly on the simple string input.\n",
    "        # This will raise GuardrailsError if a banned word is detected.\n",
    "        print(f\"Starting validation on {user_prompt}\")\n",
    "        input_ban_validator.validate(user_prompt)\n",
    "        print(f\"Done validation on {user_prompt}\")\n",
    "        \n",
    "        print(\"‚úÖ Input Guardrail: Prompt is safe and compliant (no banned terms detected).\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Input Guardrail failed due to an unexpected error: {e}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # --- OUTPUT GUARDRAIL EXECUTION (GuardrailsPII) ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üî¥ RAW LLM Output for Testing:\")\n",
    "    print(\"=\"*80)\n",
    "    print(raw_llm_output)\n",
    "    \n",
    "    print(\"\\nüü° STEP 2: Applying Output Guardrail (PII Redaction)...\")\n",
    "    \n",
    "    try:\n",
    "        output_guard = gd.Guard.from_pydantic(output_class=LLMAnswer)\n",
    "\n",
    "        # PII detection and redaction happens here.\n",
    "        outcome = output_guard.parse(llm_output=raw_llm_output)\n",
    "\n",
    "        validated_output_data: Dict[str, Any] = outcome.validated_output\n",
    "        validated_json_string = json.dumps(validated_output_data)\n",
    "        \n",
    "        # Parse the safe JSON string into the final Pydantic object\n",
    "        final_output = LLMAnswer.model_validate_json(validated_json_string)\n",
    "\n",
    "        print(\"\\n‚úÖ Output Guardrail: PII Redacted Successfully.\")\n",
    "        print(\"--- FINAL SAFE RESPONSE ---\")\n",
    "        \n",
    "        # Display the safe, structured data\n",
    "        print(final_output.model_dump_json(indent=4))\n",
    "        \n",
    "        print(\"\\n--- PII Summary ---\")\n",
    "        print(\"Redaction applied to email and phone number.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during guardrail processing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8fd95d-8609-462c-8ab4-8f58960f6d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "User Prompt Received: Can you summarize the policy details and who the contact person is?\n",
      "================================================================================\n",
      "üü° STEP 1: Applying Input Guardrail (BanList)...\n",
      "Starting validation on Can you summarize the policy details and who the contact person is?\n",
      "Done validation on Can you summarize the policy details and who the contact person is?\n",
      "‚úÖ Input Guardrail: Prompt is safe and compliant (no banned terms detected).\n",
      "\n",
      "================================================================================\n",
      "üî¥ RAW LLM Output for Testing:\n",
      "================================================================================\n",
      "{\"response\": \"The new policy details were sent to John Doe at john.doe@secure-corp.net. His mobile number is 555-867-5309. This information is confidential.\", \"context_source\": \"Policy Manual V1.2\"}\n",
      "\n",
      "üü° STEP 2: Applying Output Guardrail (PII Redaction)...\n",
      "\n",
      "‚úÖ Output Guardrail: PII Redacted Successfully.\n",
      "--- FINAL SAFE RESPONSE ---\n",
      "{\n",
      "    \"response\": \"The new policy details were sent to John Doe at <EMAIL_ADDRESS>. His mobile number is <PHONE_NUMBER>. This information is confidential.\",\n",
      "    \"context_source\": \"Policy Manual V1.2\"\n",
      "}\n",
      "\n",
      "--- PII Summary ---\n",
      "Redaction applied to email and phone number.\n",
      "\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Test 1: Safe Input (Flow should complete and redact PII) ---\n",
    "safe_input = \"Can you summarize the policy details and who the contact person is?\"\n",
    "run_guarded_flow(safe_input, generate_unsafe_llm_response())\n",
    "\n",
    "print(\"\\n\" + \"#\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fdc0d5-7f88-4ad4-b321-25c670f5eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "User Prompt Received: athena\n",
      "================================================================================\n",
      "üü° STEP 1: Applying Input Guardrail (BanList)...\n",
      "Starting validation on athena\n",
      "Done validation on athena\n",
      "‚úÖ Input Guardrail: Prompt is safe and compliant (no banned terms detected).\n",
      "\n",
      "================================================================================\n",
      "üî¥ RAW LLM Output for Testing:\n",
      "================================================================================\n",
      "{\"response\": \"The new policy details were sent to John Doe at john.doe@secure-corp.net. His mobile number is 555-867-5309. This information is confidential.\", \"context_source\": \"Policy Manual V1.2\"}\n",
      "\n",
      "üü° STEP 2: Applying Output Guardrail (PII Redaction)...\n",
      "\n",
      "‚úÖ Output Guardrail: PII Redacted Successfully.\n",
      "--- FINAL SAFE RESPONSE ---\n",
      "{\n",
      "    \"response\": \"The new policy details were sent to John Doe at <EMAIL_ADDRESS>. His mobile number is <PHONE_NUMBER>. This information is confidential.\",\n",
      "    \"context_source\": \"Policy Manual V1.2\"\n",
      "}\n",
      "\n",
      "--- PII Summary ---\n",
      "Redaction applied to email and phone number.\n"
     ]
    }
   ],
   "source": [
    "# --- Test 2: Unsafe Input (Fuzzy match test - Flow should fail at Step 1) ---\n",
    "# The term 'athena' is banned. 'a t h e n a' or 'atena' would also fail due to fuzzy search.\n",
    "unsafe_input = \"athena\"\n",
    "run_guarded_flow(unsafe_input, generate_unsafe_llm_response())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a310479e-18af-471c-9723-6d2a7ede2e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
