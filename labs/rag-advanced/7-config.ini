[Paths]
image_directory = ./rag-data/

[Models]
# Model used to "read" text from the posters (OCR). Should be a powerful vision model.
ocr_model = gpt-4o

# Model used to generate a visual description of the poster. A faster model is fine here.
description_model = gpt-4o-mini

# Model used to convert text into vectors for the database.
embedding_model = text-embedding-3-small

# Model used to generate the final answer to the user's query.
rag_model = gpt-4o

# A fast model for internal reasoning, like query analysis.
fast_reasoning_model = gpt-3.5-turbo

[Pinecone]
# The name you want to give your Pinecone index. It must be all lowercase with no hyphens.
index_name = rag-advanced-r2

[Parameters]
# Limit the number of images to process during indexing for faster testing. Set to 0 to process all.
image_limit = 100

# The number of vectors to upload to Pinecone at a time.
pinecone_batch_size = 100

# The number of relevant posters to retrieve from Pinecone for a given query.
top_k_retrieval = 3

[Prompts]
# The prompt for the OCR model to extract text from an image.
ocr_prompt = You are an expert Optical Character Recognition (OCR) system. Analyze this image and extract ALL visible text. Also extract the details of other objects from the image.

# The prompt for the description model to describe the visual elements of an image.
description_prompt = Describe the visual elements of this image

# The prompt for the final RAG agent to answer the user's question, now aware of chat history.
rag_prompt = You are a helpful expert assistant. A user has asked a question. Use the chat history for context and the retrieved images or any other details from text files to answer the user's current question. Also include their file paths if possible.
