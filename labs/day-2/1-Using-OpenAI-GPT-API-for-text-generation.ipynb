{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cb31dd",
   "metadata": {},
   "source": [
    "# üõ† Pre-trained Models and Fine-Tuning\n",
    "\n",
    "This guide walks you through two hands-on labs:  \n",
    "1. Using OpenAI‚Äôs GPT API for text generation  \n",
    "2. Fine-tuning a BERT model for sentiment analysis on a real-world dataset  \n",
    "\n",
    "## Text Generation with OpenAI‚Äôs GPT API\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- An OpenAI API key (set as environment variable `OPENAI_API_KEY`)  \n",
    "- Install the `openai` library:  \n",
    "  ```bash\n",
    "  pip install openai\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0537f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c420f2b4-6750-4ea7-96f2-af4fa8bbc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e94b2f2-1f27-48ba-a8b7-ae5418c1dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2a015c-19a5-4043-9207-a4144329d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env from home directory\n",
    "dotenv_path = os.path.expanduser(\"~/dev.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Get API key from env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95c66c1-91fd-464c-9f22-518a2aefea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u01/dev.env\n"
     ]
    }
   ],
   "source": [
    "print(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05615c49-6038-49ea-b140-612162cbf1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert \"OPENAI_API_KEY\" in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981bb2ba",
   "metadata": {},
   "source": [
    " - The temperature parameter controls the randomness of the model's output. A lower temperature results in more predictable, focused text, while a higher temperature produces more creative and unexpected results.\n",
    "\n",
    "   - Use low temperature for tasks that require factual, consistent answers, like summarization, question-answering, or code generation.\n",
    "\n",
    "   - Use high temperature for creative tasks like writing stories, brainstorming ideas, or generating diverse marketing copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126b34d",
   "metadata": {},
   "source": [
    "### top_p\n",
    "- If you set top_p = 0.90 (or 90%):\n",
    "   - The model will sum the probabilities: 0.60 (the) + 0.25 (a) = 0.85. Since 0.85 is still less than 0.90, it adds the next word: 0.85 + 0.10 (one) = 0.95. This total now exceeds the 0.90 threshold.\n",
    "\n",
    "   - As a result, the model will only choose its next word from the pool of {\"the\", \"a\", \"one\"} and will completely ignore \"that\" and all less likely options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb82261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "def generate_text(prompt: str,\n",
    "                  model: str = \"gpt-3.5-turbo\",\n",
    "                  max_tokens: int = 100,            # sets the maximum number of tokens the model can generate for its response.\n",
    "                  temperature: float = 0.7,\n",
    "                  top_p: float = 1.0,\n",
    "                  n_samples: int = 1):\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        n=n_samples\n",
    "    )\n",
    "\n",
    "    return [choice.message.content.strip() for choice in response.choices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8203e-ec6a-4413-ac53-37b85bd2ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What do you think about future life quality?\"\n",
    "outputs = generate_text(prompt, max_tokens=50, temperature=0.5, n_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73a08f3-f626-4e3d-b58d-69d933faaa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 1 ===\n",
      "The future of life quality is a complex and multifaceted issue that will be influenced by a wide range of factors, including technological advancements, environmental sustainability, economic development, and social equality. It is important that we work towards creating a future where all\n",
      "\n",
      "=== Sample 2 ===\n",
      "I believe that future life quality will depend on how we address current global challenges such as climate change, inequality, and technological advancements. If we prioritize sustainability, social justice, and ethical use of technology, we have the potential to improve quality of life for\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(outputs, 1):\n",
    "    print(f\"\\n=== Sample {i} ===\\n{text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17eb827",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Run it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f6d1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Experimenting with Parameters\n",
    "\n",
    "- **`temperature`**: Higher values (0.8‚Äì1.0) ‚Üí more creative outputs; lower (0.2‚Äì0.5) ‚Üí more focused.  \n",
    "- **`max_tokens`**: Limits response length.  \n",
    "- **`top_p`** (nucleus sampling): Restricts vocabulary to cumulative probability _p_.  \n",
    "- **`n`**: Number of samples to generate per prompt.\n",
    "\n",
    "> üí° Try generating three variations of a product description by setting `n_samples=3` and compare diversity.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Advanced: Chat Completions (GPT-3.5 / GPT-4)\n",
    "\n",
    "OpenAI‚Äôs chat endpoint uses a list of messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a37b2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electric vehicles offer several benefits compared to traditional gasoline-powered vehicles. Some of the key advantages include:\n",
      "\n",
      "1. Environmental impact: Electric vehicles produce zero tailpipe emissions, reducing air pollution and greenhouse gas emissions that contribute to climate change. This can help improve air quality and reduce the overall carbon footprint of transportation.\n",
      "\n",
      "2. Energy efficiency: Electric vehicles are more energy-efficient than internal combustion engine vehicles, as they convert a higher percentage of energy from the grid to power the vehicle. This can result in lower energy consumption and reduced operating costs.\n",
      "\n",
      "3. Lower operating costs: Electric vehicles have fewer moving parts than traditional vehicles, which can lead to lower maintenance costs over the lifetime of the vehicle. Additionally, electricity is often cheaper than gasoline, resulting in lower fuel costs for\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain the benefits of electric vehicles.\"}\n",
    "    ],\n",
    "    max_tokens=150,\n",
    "    temperature=0.6\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d6082",
   "metadata": {},
   "source": [
    "> üîç Notice how you can steer tone and style with the ‚Äúsystem‚Äù message.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
