{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"C:\\\\Users\\\\adminuser\\\\dev.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key is set and starts with: sk-proj-...\n"
     ]
    }
   ],
   "source": [
    "# It's a good practice to verify that the API key has been loaded correctly.\n",
    "# This check is for the OpenAI key, but you can adapt it for any other service (e.g., 'GOOGLE_API_KEY').\n",
    "# Note: Ollama runs locally and does not require an API key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    # Print only the first few characters for security.\n",
    "    print(f\"OpenAI API Key is set and starts with: {openai_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not found. Please check the .env file and the setup guide.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The core import for interacting with OpenAI's models.\n",
    "# LangChain uses this same structure to provide a unified interface for various LLMs (like Gemini, Claude, etc.).\n",
    "# This makes it easy to switch between different model providers.\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI client.\n",
    "# This object is the main entry point for making API calls.\n",
    "# For other providers (like Google's Gemini or local models via Ollama), the instantiation would be different.\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All conversations with the API are structured as a list of message objects.\n",
    "# Each message has a 'role' ('user', 'assistant', or 'system') and 'content'.\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# Now, let's send the request to the model.\n",
    "# Model Selection: 'gpt-4o-mini' is a great choice for balancing cost, speed, and intelligence.\n",
    "# Other options include 'gpt-4o' (most powerful), 'gpt-4-turbo', or free local models via Ollama.\n",
    "# The model choice can significantly impact the response quality and cost.\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", # A powerful and cost-effective model\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# The response content is nested within the 'choices' list.\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a two-step conversation.\n",
    "# Step 1: Ask the LLM to generate a challenging question.\n",
    "\n",
    "question_prompt = \"Propose a hard, challenging question to assess someone's logical reasoning. Respond only with the question itself.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Question:\n",
      "A farmer has a fox, a chicken, and a bag of grain. He needs to cross a river with all three, but his boat can only carry himself and one other item at a time. If left alone together, the fox will eat the chicken and the chicken will eat the grain. How can the farmer safely transport all three across the river?\n"
     ]
    }
   ],
   "source": [
    "# Send the request to get the question.\n",
    "# Using a slightly more powerful model might yield a more creative question.\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "generated_question = response.choices[0].message.content\n",
    "\n",
    "print(f\"Generated Question:\\n{generated_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Now, use the generated question as a new prompt to get an answer.\n",
    "messages = [{\"role\": \"user\", \"content\": generated_question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer:\n",
      "The farmer can safely transport the fox, chicken, and bag of grain across the river by following these steps:\n",
      "\n",
      "1. The farmer takes the chicken across the river first and leaves the fox and the grain on the starting side.\n",
      "2. The farmer goes back alone to the starting side.\n",
      "3. The farmer then takes the fox across the river.\n",
      "4. The farmer leaves the fox on the other side, but he takes the chicken back with him to the starting side.\n",
      "5. The farmer leaves the chicken on the starting side and takes the grain across the river.\n",
      "6. The farmer leaves the grain with the fox on the other side and goes back alone to the starting side.\n",
      "7. Finally, the farmer takes the chicken across the river one last time.\n",
      "\n",
      "Now all three items — the fox, chicken, and bag of grain — are safely across the river without any being eaten.\n"
     ]
    }
   ],
   "source": [
    "# Ask the model to answer its own question.\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"Generated Answer:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_prompt = f\"\"\"\n",
    "Role: You are a validator to validate the responses of the question and suggest the improvements.\n",
    "\n",
    "You need to validate below question and the answer to that question is just below thtat particular question itself.\n",
    "Question: {generated_question}\n",
    "\n",
    "Answer: {answer}\n",
    "\n",
    "\n",
    "After validation, give your feedback and the improvements need to be done to the answer. In case you have better answer then provide that as well.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Step 2: Now, use the generated question as a new prompt to get an answer.\n",
    "messages = [{\"role\": \"user\", \"content\": validation_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer:\n",
      "**Validation of the Answer:**\n",
      "\n",
      "The steps outlined in the answer accurately represent a solution to the problem presented in the question. The farmer successfully transports each item across the river without any of them being left alone in a way that leads to predation (the fox eating the chicken or the chicken eating the grain). \n",
      "\n",
      "**Feedback and Improvements:**\n",
      "\n",
      "1. **Clarity and Structure:** The answer is clear and logical, but it could benefit from being broken down into more distinct sections for easier reading. Each step could be numbered or listed more clearly to emphasize the sequence of actions.\n",
      "\n",
      "2. **Explanation of Strategy:** While the steps are correct, the answer could include a brief explanation or rationale for why each step is taken. For example, explaining why the chicken is taken first (to prevent it from being eaten) would enhance understanding.\n",
      "\n",
      "3. **Visual Aid:** Sometimes adding a diagram or a visual representation of the crossings could help to clarify how the items are transported.\n",
      "\n",
      "4. **Reinforcement of Safety:** The answer could reinforce at the end that at no point was any item left alone in a way that would cause harm, to reassure the reader.\n",
      "\n",
      "**Revised Answer Example:**\n",
      "\n",
      "The farmer can safely transport the fox, chicken, and bag of grain across the river by following these steps:\n",
      "\n",
      "1. **First Crossing:** The farmer takes the chicken across the river first, leaving the fox and the grain on the starting side. *(This is crucial to ensure the fox cannot eat the chicken).*\n",
      "   \n",
      "2. **Return Alone:** The farmer goes back alone to the starting side.\n",
      "\n",
      "3. **Second Crossing:** The farmer takes the fox across the river.\n",
      "\n",
      "4. **Taking Chicken Back:** The farmer leaves the fox on the other side but takes the chicken back with him to the starting side. *(He takes the chicken back to avoid it being left alone with the fox.)*\n",
      "\n",
      "5. **Third Crossing:** The farmer leaves the chicken on the starting side and takes the grain across the river.\n",
      "\n",
      "6. **Final Return:** The farmer leaves the grain with the fox on the other side and returns alone to the starting side.\n",
      "\n",
      "7. **Final Crossing:** Finally, the farmer takes the chicken across the river one last time.\n",
      "\n",
      "By following these steps, the farmer successfully ensures that all three items — the fox, the chicken, and the bag of grain — are safely transported across the river without any being eaten.\n"
     ]
    }
   ],
   "source": [
    "# Ask the model to answer its own question.\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"Generated Answer:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Validation of the Answer:**\n",
       "\n",
       "The steps outlined in the answer accurately represent a solution to the problem presented in the question. The farmer successfully transports each item across the river without any of them being left alone in a way that leads to predation (the fox eating the chicken or the chicken eating the grain). \n",
       "\n",
       "**Feedback and Improvements:**\n",
       "\n",
       "1. **Clarity and Structure:** The answer is clear and logical, but it could benefit from being broken down into more distinct sections for easier reading. Each step could be numbered or listed more clearly to emphasize the sequence of actions.\n",
       "\n",
       "2. **Explanation of Strategy:** While the steps are correct, the answer could include a brief explanation or rationale for why each step is taken. For example, explaining why the chicken is taken first (to prevent it from being eaten) would enhance understanding.\n",
       "\n",
       "3. **Visual Aid:** Sometimes adding a diagram or a visual representation of the crossings could help to clarify how the items are transported.\n",
       "\n",
       "4. **Reinforcement of Safety:** The answer could reinforce at the end that at no point was any item left alone in a way that would cause harm, to reassure the reader.\n",
       "\n",
       "**Revised Answer Example:**\n",
       "\n",
       "The farmer can safely transport the fox, chicken, and bag of grain across the river by following these steps:\n",
       "\n",
       "1. **First Crossing:** The farmer takes the chicken across the river first, leaving the fox and the grain on the starting side. *(This is crucial to ensure the fox cannot eat the chicken).*\n",
       "   \n",
       "2. **Return Alone:** The farmer goes back alone to the starting side.\n",
       "\n",
       "3. **Second Crossing:** The farmer takes the fox across the river.\n",
       "\n",
       "4. **Taking Chicken Back:** The farmer leaves the fox on the other side but takes the chicken back with him to the starting side. *(He takes the chicken back to avoid it being left alone with the fox.)*\n",
       "\n",
       "5. **Third Crossing:** The farmer leaves the chicken on the starting side and takes the grain across the river.\n",
       "\n",
       "6. **Final Return:** The farmer leaves the grain with the fox on the other side and returns alone to the starting side.\n",
       "\n",
       "7. **Final Crossing:** Finally, the farmer takes the chicken across the river one last time.\n",
       "\n",
       "By following these steps, the farmer successfully ensures that all three items — the fox, the chicken, and the bag of grain — are safely transported across the river without any being eaten."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For better readability in notebooks, we can render the output as Markdown.\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "This was a successful first step into the world of Agentic AI. The environment is set up and working correctly.\n",
    "\n",
    "Next, we can explore more complex interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: A 3-Step Agentic Workflow\n",
    "\n",
    "Let's try a simple commercial application using a chain of LLM calls:\n",
    "1.  **Ideation**: Ask the LLM to identify a business sector ripe for an Agentic AI solution.\n",
    "2.  **Problem Discovery**: Ask the LLM to describe a specific, challenging pain point within that sector.\n",
    "3.  **Solution Proposal**: Ask the LLM to propose an Agentic AI system to solve that pain point.\n",
    "\n",
    "Below is a complete, working example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Identify a business area ---\n",
    "prompt1 = \"Which business sector could significantly benefit from an Agentic AI solution? Respond with the sector name only.\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt1}]\n",
    "\n",
    "response1 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "business_sector = response1.choices[0].message.content.strip()\n",
    "print(f\"1. Identified Sector: {business_sector}\\n\")\n",
    "\n",
    "# --- Step 2: Identify a pain point in that area ---\n",
    "prompt2 = f\"What is a major, unsolved pain point in the '{business_sector}' industry? Describe it clearly and concisely.\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt2}]\n",
    "\n",
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "pain_point = response2.choices[0].message.content.strip()\n",
    "print(f\"2. Identified Pain Point:\\n{pain_point}\\n\")\n",
    "\n",
    "# --- Step 3: Propose an Agentic AI solution ---\n",
    "prompt3 = f\"Considering the pain point in '{business_sector}': '{pain_point}'. Propose a high-level concept for an Agentic AI system that could solve this. Describe its key functions and agents.\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt3}]\n",
    "\n",
    "response3 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7 # Add some creativity to the solution\n",
    ")\n",
    "solution = response3.choices[0].message.content.strip()\n",
    "print(f\"3. Proposed Agentic AI Solution:\")\n",
    "display(Markdown(solution))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
