{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Building an AI Agent with LangChain: A Detailed Step-by-Step Guide\n",
    "\n",
    "Welcome! This notebook provides a detailed, beginner-friendly guide to building your first AI Agent using the LangChain framework. An AI Agent can do more than just chat; it can use **tools** to interact with the outside world, look up information, and perform actions.\n",
    "\n",
    "### Lab Objectives:\n",
    "By the end of this lab, you will have:\n",
    "1.  **Set up** a Python environment with LangChain and connected it to an LLM (OpenAI).\n",
    "2.  **Created and tested custom tools** for the agent (Wikipedia Search and a Calculator).\n",
    "3.  **Built an Agent** that can intelligently decide which tool to use based on your question.\n",
    "4.  **Added Memory** to the agent so it can remember previous parts of your conversation.\n",
    "5.  **Observed the agent's reasoning process** step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1: Install Required Libraries\n",
    "\n",
    "First, we need to install the necessary Python packages. We'll add `python-dotenv` to help manage our API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.16 in c:\\venv\\lib\\site-packages (0.1.16)\n",
      "Requirement already satisfied: langchain-core==0.1.42 in c:\\venv\\lib\\site-packages (0.1.42)\n",
      "Requirement already satisfied: langchain-openai in c:\\venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: requests in c:\\venv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numexpr in c:\\venv\\lib\\site-packages (2.14.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (0.6.7)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (0.0.32)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (8.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (4.0.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (0.1.147)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (2.0.44)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (2.12.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (3.13.2)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (0.0.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (1.26.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (6.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\venv\\lib\\site-packages (from langchain==0.1.16) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\venv\\lib\\site-packages (from langchain-core==0.1.42) (23.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\venv\\lib\\site-packages (from langchain-openai) (2.7.1)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
      "  Downloading langchain_openai-1.0.0-py3-none-any.whl (80 kB)\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
      "  Downloading langchain_openai-0.3.34-py3-none-any.whl (75 kB)\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "  Downloading langchain_openai-0.3.32-py3-none-any.whl (74 kB)\n",
      "Collecting openai<2.0.0,>=1.99.9\n",
      "  Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
      "  Downloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
      "  Downloading langchain_openai-0.3.29-py3-none-any.whl (74 kB)\n",
      "  Using cached langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "  Downloading langchain_openai-0.3.27-py3-none-any.whl (70 kB)\n",
      "  Downloading langchain_openai-0.3.26-py3-none-any.whl (70 kB)\n",
      "  Downloading langchain_openai-0.3.25-py3-none-any.whl (69 kB)\n",
      "  Downloading langchain_openai-0.3.24-py3-none-any.whl (68 kB)\n",
      "  Downloading langchain_openai-0.3.23-py3-none-any.whl (65 kB)\n",
      "  Downloading langchain_openai-0.3.22-py3-none-any.whl (65 kB)\n",
      "  Downloading langchain_openai-0.3.21-py3-none-any.whl (65 kB)\n",
      "  Downloading langchain_openai-0.3.20-py3-none-any.whl (64 kB)\n",
      "  Downloading langchain_openai-0.3.19-py3-none-any.whl (64 kB)\n",
      "  Downloading langchain_openai-0.3.18-py3-none-any.whl (63 kB)\n",
      "  Downloading langchain_openai-0.3.17-py3-none-any.whl (62 kB)\n",
      "  Downloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
      "  Downloading langchain_openai-0.3.15-py3-none-any.whl (62 kB)\n",
      "  Downloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
      "  Downloading langchain_openai-0.3.13-py3-none-any.whl (61 kB)\n",
      "  Downloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
      "  Downloading langchain_openai-0.3.11-py3-none-any.whl (60 kB)\n",
      "  Downloading langchain_openai-0.3.10-py3-none-any.whl (61 kB)\n",
      "  Downloading langchain_openai-0.3.9-py3-none-any.whl (60 kB)\n",
      "  Downloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
      "  Downloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
      "  Downloading langchain_openai-0.3.5-py3-none-any.whl (54 kB)\n",
      "  Downloading langchain_openai-0.3.4-py3-none-any.whl (54 kB)\n",
      "  Downloading langchain_openai-0.3.3-py3-none-any.whl (54 kB)\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl (54 kB)\n",
      "  Downloading langchain_openai-0.3.1-py3-none-any.whl (54 kB)\n",
      "  Downloading langchain_openai-0.3.0-py3-none-any.whl (54 kB)\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.13-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.11-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.9-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.8-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.7-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.6-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.5-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.4-py3-none-any.whl (50 kB)\n",
      "  Downloading langchain_openai-0.2.3-py3-none-any.whl (49 kB)\n",
      "  Downloading langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
      "  Downloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "  Downloading langchain_openai-0.1.24-py3-none-any.whl (51 kB)\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
      "  Downloading langchain_openai-0.1.22-py3-none-any.whl (51 kB)\n",
      "  Downloading langchain_openai-0.1.20-py3-none-any.whl (48 kB)\n",
      "  Downloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\n",
      "  Downloading langchain_openai-0.1.17-py3-none-any.whl (46 kB)\n",
      "  Downloading langchain_openai-0.1.16-py3-none-any.whl (46 kB)\n",
      "  Downloading langchain_openai-0.1.15-py3-none-any.whl (46 kB)\n",
      "  Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
      "  Downloading langchain_openai-0.1.13-py3-none-any.whl (45 kB)\n",
      "  Downloading langchain_openai-0.1.12-py3-none-any.whl (43 kB)\n",
      "  Downloading langchain_openai-0.1.11-py3-none-any.whl (40 kB)\n",
      "  Downloading langchain_openai-0.1.10-py3-none-any.whl (40 kB)\n",
      "  Downloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "  Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
      "  Downloading langchain_openai-0.1.5-py3-none-any.whl (34 kB)\n",
      "  Downloading langchain_openai-0.1.4-py3-none-any.whl (33 kB)\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\venv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\venv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\venv\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\venv\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.22.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (0.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\venv\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (3.26.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.11.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.16.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\venv\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\venv\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\venv\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\venv\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.3.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.16) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.16) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.16) (0.7.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: colorama in c:\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.99.9->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (1.1.0)\n",
      "Installing collected packages: openai, langchain-openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 2.7.1\n",
      "    Uninstalling openai-2.7.1:\n",
      "      Successfully uninstalled openai-2.7.1\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 1.0.2\n",
      "    Uninstalling langchain-openai-1.0.2:\n",
      "      Successfully uninstalled langchain-openai-1.0.2\n",
      "Successfully installed langchain-openai-0.1.3 openai-1.109.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install \"langchain==0.1.16\" \"langchain-core==0.1.42\" langchain-openai requests python-dotenv numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.2: Set Up the OpenAI API Key\n",
    "\n",
    "This code loads your OpenAI API key from a `.env` file located in the same directory as the notebook. \n",
    "\n",
    "**Instructions for local setup:**\n",
    "1. Create a file named `.env` in the same folder as this notebook.\n",
    "2. Add the following line to the `.env` file, replacing the placeholder with your actual key:\n",
    "   `OPENAI_API_KEY=\"sk-YourActualKeyHere\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI API Key loaded successfully from .env file!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "dotenv_path = os.path.expanduser(\"~/dev.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Get the API key from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"âš ï¸ OpenAI API Key not found. Make sure you have a .env file in the same directory with your key.\")\n",
    "else:\n",
    "    # Set the key for the LangChain library to use\n",
    "    os.environ['OPENAI_API_KEY'] = api_key\n",
    "    print(\"âœ… OpenAI API Key loaded successfully from .env file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Creating a Custom Tool\n",
    "\n",
    "Tools are functions that an agent can use to get information or perform actions outside of its own knowledge. Our first tool will be a simple function to search Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1: Define the Tool's Functionality\n",
    "\n",
    "Let's create a standard Python function that takes a topic and uses the Wikipedia API to fetch a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "def wiki_search(topic: str) -> str:\n",
    "    \"\"\"Fetches a summary from the English Wikipedia for a given topic.\"\"\"\n",
    "    \n",
    "    base_url = \"https://en.wikipedia.org/api/rest_v1/page/summary/\"\n",
    "    encoded_topic = quote(topic.strip())  # Encode spaces and special characters\n",
    "    \n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"User-Agent\": \"WikiSearchBot/1.0 (https://github.com/yourusername; contact@example.com)\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with requests.Session() as session:\n",
    "            response = session.get(base_url + encoded_topic, headers=headers, timeout=10)\n",
    "            response.raise_for_status()  # Raise for 4xx/5xx responses\n",
    "            \n",
    "            data = response.json()\n",
    "            return data.get(\"extract\", \"No summary available.\")\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        return f\"HTTP error: {e.response.status_code} - {e.response.reason}\"\n",
    "    except requests.exceptions.Timeout:\n",
    "        return \"Request timed out. Please try again.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error fetching data: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2: Test the Raw Function\n",
    "\n",
    "Before giving the function to our agent, let's make sure it works on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the wiki_search function...\n",
      "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing the wiki_search function...\")\n",
    "summary = wiki_search(\"LangChain\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3: Wrap the Function as a LangChain Tool\n",
    "\n",
    "Now, we wrap our Python function in a LangChain `Tool` object. This is how the agent recognizes it.\n",
    "\n",
    "**This is a critical step!** The `description` field is what the agent's LLM brain reads to decide **when** to use this tool. A good description is essential for the agent to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "wiki_tool = Tool(\n",
    "    name=\"wiki_search\",\n",
    "    func=wiki_search, # The function the tool will execute\n",
    "    description=\"Use this tool to get a summary of any topic from Wikipedia. Input should be a search term.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Debugging)** Let's inspect the created tool to see its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: wiki_search\n",
      "Tool Description: Use this tool to get a summary of any topic from Wikipedia. Input should be a search term.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tool Name: {wiki_tool.name}\")\n",
    "print(f\"Tool Description: {wiki_tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Initializing the LLM\n",
    "\n",
    "The agent's \"brain\" is a Large Language Model (LLM). We'll instantiate the OpenAI LLM wrapper from LangChain. The `temperature` parameter controls the creativity of the model's responses (0.0 is very deterministic, 1.0 is very creative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM Initialized.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0.2, # Lower temperature for more factual responses\n",
    "    openai_api_key=os.environ.get('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "print(\"âœ… LLM Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Creating and Running the Agent\n",
    "\n",
    "Now we assemble the components: the LLM (brain) and the tools (actions). We will use a **ReAct Agent**, which stands for \"Reasoning and Acting.\" It works by thinking step-by-step to decide what to do.\n",
    "\n",
    "Setting `verbose=True` is crucial for debugging, as it shows us the agent's chain of thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# ZERO_SHOT_REACT_DESCRIPTION: defines a type of agent that decides which tool to use based only on the tool's description. It uses the ReAct framework to reason step-by-step to find an answer.\n",
    "# ZERO_SHOT: The agent doesn't need to see any examples of how to solve a problem. It figures out what to do on the fly based on your prompt and the tools it has.\n",
    "\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Define the list of tools our agent can use\n",
    "tools = [wiki_tool]\n",
    "\n",
    "# Create the agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True # Set to True to see the agent's thought process\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1: Test the Agent\n",
    "\n",
    "Let's ask a question that requires looking up information. Watch the output from `verbose=True` to see how the agent thinks:\n",
    "1.  **Thought:** The agent thinks about whether it needs a tool.\n",
    "2.  **Action:** It decides to use the `wiki_search` tool.\n",
    "3.  **Action Input:** It determines what to search for.\n",
    "4.  **Observation:** It gets the result back from the tool.\n",
    "5.  **Thought:** It thinks about the final answer based on the observation.\n",
    "6.  **Final Answer:** It gives you the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query: Tell me about the planet Mars.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use wiki_search to get information about Mars.\n",
      "Action: wiki_search\n",
      "Action Input: Mars\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMars is the fourth planet from the Sun. It is also known as the \"Red Planet\", for its orange-red appearance. Mars is a desert-like rocky planet with a tenuous atmosphere that is primarily carbon dioxide. At the average surface level the atmospheric pressure is a few thousandths of Earthâ€™s, atmospheric temperature ranges from âˆ’153 to 20Â Â°C, and cosmic radiation is high. Mars retains some water, in the ground as well as thinly in the atmosphere, forming cirrus clouds, fog, frost, larger polar regions of permafrost and ice caps, but no bodies of liquid surface water. Its surface gravity is roughly a third of Earth's or double that of the Moon. It is about half the Earth in width, or twice the Moon, with a diameter of 6,779Â km (4,212Â mi), and has a surface area the size of all the dry land of Earth.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is interesting information, but I want to know more about Mars.\n",
      "Action: wiki_search\n",
      "Action Input: Mars\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMars is the fourth planet from the Sun. It is also known as the \"Red Planet\", for its orange-red appearance. Mars is a desert-like rocky planet with a tenuous atmosphere that is primarily carbon dioxide. At the average surface level the atmospheric pressure is a few thousandths of Earthâ€™s, atmospheric temperature ranges from âˆ’153 to 20Â Â°C, and cosmic radiation is high. Mars retains some water, in the ground as well as thinly in the atmosphere, forming cirrus clouds, fog, frost, larger polar regions of permafrost and ice caps, but no bodies of liquid surface water. Its surface gravity is roughly a third of Earth's or double that of the Moon. It is about half the Earth in width, or twice the Moon, with a diameter of 6,779Â km (4,212Â mi), and has a surface area the size of all the dry land of Earth.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Mars is the fourth planet from the Sun, with a desert-like rocky surface and a tenuous atmosphere primarily made up of carbon dioxide. It has a diameter of 6,779 km and a surface area the size of all the dry land on Earth.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mars is the fourth planet from the Sun, with a desert-like rocky surface and a tenuous atmosphere primarily made up of carbon dioxide. It has a diameter of 6,779 km and a surface area the size of all the dry land on Earth.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Tell me about the planet Mars.\"\n",
    "print(f\"Executing query: {query}\")\n",
    "agent.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Adding Memory to the Agent\n",
    "\n",
    "By default, the agent is **stateless**â€”it forgets everything after answering a question. Let's add memory so we can have a real conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory object created.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# The memory_key must match the input variable in the agent's prompt\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "print(\"âœ… Memory object created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we re-initialize the agent, this time passing the `memory` object. We also change the `AgentType` to one that is optimized for conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent with memory created.\n"
     ]
    }
   ],
   "source": [
    "agent_with_memory = initialize_agent(\n",
    "    tools=tools, \n",
    "    llm=llm, \n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "    memory=memory, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent with memory created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.1: Test the Conversational Agent\n",
    "\n",
    "Let's test it with a follow-up question. The agent should now be able to use the context from the first question to understand the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: wiki_search\n",
      "Action Input: Ada Lovelace\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAugusta Ada King, Countess of Lovelace, also known as Ada Lovelace, was an English mathematician and writer chiefly known for her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation. Ada Lovelace is sometimes considered to be the first computer programmer.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: Ada Lovelace was a pioneering mathematician and writer who is often considered to be the first computer programmer. She worked on Charles Babbage's Analytical Engine and recognized its potential for applications beyond just calculation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ada Lovelace was a pioneering mathematician and writer who is often considered to be the first computer programmer. She worked on Charles Babbage's Analytical Engine and recognized its potential for applications beyond just calculation.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First question\n",
    "agent_with_memory.run(\"Who was Ada Lovelace?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: wiki_search\n",
      "Action Input: Ada Lovelace\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAugusta Ada King, Countess of Lovelace, also known as Ada Lovelace, was an English mathematician and writer chiefly known for her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation. Ada Lovelace is sometimes considered to be the first computer programmer.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: Ada Lovelace lived from December 10, 1815 to November 27, 1852.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ada Lovelace lived from December 10, 1815 to November 27, 1852.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Follow-up question\n",
    "# The agent should know that \"she\" refers to Ada Lovelace from the previous turn.\n",
    "agent_with_memory.run(\"When did she live?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Debugging)** Let's inspect the memory buffer to see what the agent has remembered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who was Ada Lovelace?\n",
      "AI: Ada Lovelace was a pioneering mathematician and writer who is often considered to be the first computer programmer. She worked on Charles Babbage's Analytical Engine and recognized its potential for applications beyond just calculation.\n",
      "Human: Who was Ada Lovelace?\n",
      "AI: Ada Lovelace was a pioneering mathematician and writer who is often considered to be the first computer programmer. She worked on Charles Babbage's Analytical Engine and recognized its potential for applications beyond just calculation.\n",
      "Human: When did she live?\n",
      "AI: Ada Lovelace lived from December 10, 1815 to November 27, 1852.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Extending the Agent with a Calculator Tool\n",
    "\n",
    "An agent's power comes from having multiple tools. Let's add a calculator. LLMs are notoriously bad at math, so giving them a calculator tool is a common and effective pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Calculator tool created.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "# LLMMathChain is a pre-built tool that is much safer than using Python's eval()\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "\n",
    "calc_tool = Tool(\n",
    "    name=\"Calculator\",\n",
    "    func=llm_math_chain.run,\n",
    "    description=\"Use this tool to evaluate any mathematical expression.\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Calculator tool created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a new agent that has access to **both** the Wikipedia tool and the Calculator tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-tool agent created.\n"
     ]
    }
   ],
   "source": [
    "multi_tool_memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "tools_multi = [wiki_tool, calc_tool]\n",
    "\n",
    "multi_tool_agent = initialize_agent(\n",
    "    tools=tools_multi,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=multi_tool_memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Multi-tool agent created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1: Test the Multi-Tool Agent\n",
    "\n",
    "Let's see if the agent can correctly choose the right tool for different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: 128 * 7\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "128 * 7\u001b[32;1m\u001b[1;3m```text\n",
      "128 * 7\n",
      "```\n",
      "...numexpr.evaluate(\"128 * 7\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m896\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 896\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: 128 multiplied by 7 is equal to 896. Is there anything else you would like to know?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'128 multiplied by 7 is equal to 896. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should use the Calculator tool\n",
    "multi_tool_agent.run(\"What is 128 multiplied by 7?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: wiki_search\n",
      "Action Input: Alan Turing\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAlan Mathison Turing was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: Alan Turing was a brilliant mathematician and computer scientist who made significant contributions to the field of theoretical computer science. He is often referred to as the father of theoretical computer science and is known for his work on the Turing machine, which is considered a model of a general-purpose computer.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Alan Turing was a brilliant mathematician and computer scientist who made significant contributions to the field of theoretical computer science. He is often referred to as the father of theoretical computer science and is known for his work on the Turing machine, which is considered a model of a general-purpose computer.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should use the wiki_search tool\n",
    "multi_tool_agent.run(\"And who is Alan Turing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion & Next Steps\n",
    "\n",
    "Congratulations! You have successfully built a conversational AI agent that can use multiple tools to answer questions and perform tasks. \n",
    "\n",
    "#### Key Takeaways:\n",
    "1.  **Agents = LLM (Brain) + Tools (Actions)**: The core idea is to give a language model the ability to interact with external systems.\n",
    "2.  **Tool Descriptions are Crucial**: The agent decides which tool to use based on the `description` you provide. Make them clear and specific.\n",
    "3.  **Memory Enables Conversation**: Without memory, each query is isolated. Memory provides context for follow-up questions.\n",
    "4.  **`verbose=True` is Your Best Friend**: It's essential for understanding and debugging the agent's reasoning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Building_an_AI_Agent_with_LangChain_Generic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
