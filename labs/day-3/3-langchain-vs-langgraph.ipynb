{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: LangChain vs. LangGraph - The Self-Correcting AI Researcher\n",
    "\n",
    "**Objective:** To understand the practical differences between a standard `AgentExecutor` and `LangGraph` for building complex, stateful AI agents.\n",
    "\n",
    "In this notebook, we will attempt to build an agent with a crucial capability: **self-correction**. The agent's task is to research a topic, but with a twist. It must:\n",
    "1. Perform an initial web search.\n",
    "2. **Analyze** its own search results to see if they are good enough.\n",
    "3. If the results are poor, it must **rewrite** its search query and try again.\n",
    "4. Only when it has sufficient information should it provide a final answer.\n",
    "\n",
    "This cyclical, self-evaluating behavior is a hallmark of more advanced, reliable agents. We will see how a standard agent struggles with this task and how LangGraph is explicitly designed to solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's install the necessary libraries. We will use `ddgs` for DuckDuckGo search as the older package is deprecated. Then we'll import our modules and set up the environment. Make sure you have a `.env` file in the same directory with your `OPENAI_API_KEY`, or set it up as a secret in your Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain-openai langgraph langchain_community ddgs python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Dependencies installed and environment loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The LangChain Agent Attempt (The Brittle Approach)\n",
    "\n",
    "Here, we'll try to force a standard `AgentExecutor` to perform the self-correction loop by cramming all the logic into a complex prompt. We are essentially *telling* the agent to follow our steps, but we cannot *enforce* it.\n",
    "\n",
    "**Hypothesis:** The agent will likely struggle to follow the cyclical instructions. It is heavily biased towards moving forward to a `Final Answer` and may ignore the command to loop back, especially if the initial results are weak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Define Tools and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Tool: The agent only has one tool, a web search.\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "tools = [search_tool]\n",
    "\n",
    "# LLM: Using a powerful model to give it the best chance.\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: The Complex Prompt\n",
    "\n",
    "This is the core of the attempt. We modify a standard ReAct prompt to include a detailed, multi-step procedure. The agent's ability to follow these instructions is entirely dependent on the LLM's interpretation, making it unreliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Pull a base ReAct prompt\n",
    "prompt_template = hub.pull(\"hwchase17/react\").copy()\n",
    "\n",
    "# Manually inject our complex, cyclical instructions\n",
    "prompt_template.template = \"\"\"\n",
    "You are an expert web researcher. Your goal is to provide a comprehensive answer. You MUST follow these steps precisely:\n",
    "\n",
    "Step 1: Initial Search. Use the search tool with a query based on the user's topic.\n",
    "Step 2: Critical Analysis. After getting the search results, you MUST pause and analyze them. Ask yourself: 'Are these results detailed enough to write a good answer?'\n",
    "Step 3: Decision and Self-Correction. \n",
    "- If the results ARE sufficient, proceed to Step 4.\n",
    "- If the results ARE NOT sufficient, you MUST formulate a new, more specific search query and go back to Step 1. This is a critical self-correction step.\n",
    "\n",
    "Step 4: Final Answer. Once you have sufficient information, synthesize it into a final, detailed answer.\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: your reasoning and plan for the next action (following the steps above)\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat multiple times)\n",
    "Thought: I now have enough information to answer the user's question.\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Create and Run the Agent\n",
    "\n",
    "Now we assemble the agent and run it. Observe the `verbose` output carefully to see if it follows our instructions. The final output will be rendered as Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Create the Agent\n",
    "agent_v1 = create_react_agent(llm, tools, prompt_template)\n",
    "agent_executor_v1 = AgentExecutor(agent=agent_v1, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# Let's run it with a niche topic that likely requires re-searching\n",
    "topic = \"The impact of LangGraph on multi-agent system reliability compared to traditional agent loops\"\n",
    "response_v1 = agent_executor_v1.invoke({\"input\": topic})\n",
    "\n",
    "# Render the final output as Markdown\n",
    "print(\"\\n--- Agent's Final Answer (Formatted as Markdown) ---\")\n",
    "display(Markdown(response_v1['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: Analysis of the LangChain Agent's Performance\n",
    "\n",
    "You will likely observe that the agent performs one search and then immediately proceeds to a `Final Answer`, even if the results are clearly insufficient. It fails to follow the instruction to loop back.\n",
    "\n",
    "**The core problem is the lack of control.** We are *suggesting* a workflow in the prompt, but the `AgentExecutor`'s fundamental design doesn't support enforcing this kind of cycle. This is a classic example of a workflow that is **not feasible** to implement reliably with this architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The LangGraph Solution (The Robust Approach)\n",
    "\n",
    "Now, let's build the same agent using LangGraph. Instead of a complex prompt, we will define our workflow as an explicit graph of nodes and edges.\n",
    "\n",
    "**Hypothesis:** The LangGraph implementation will reliably execute the self-correction loop every time it's needed, because the flow is enforced by code, not suggested by a prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Define the State\n",
    "\n",
    "The `State` is a central concept in LangGraph. It's a single object (in this case, a dictionary) that gets passed between all the nodes in our graph. Each node can read from it and write to it, allowing us to track our progress through the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Represents the state of our research agent.\"\"\"\n",
    "    topic: str\n",
    "    messages: Annotated[List[BaseMessage], lambda x, y: x + y]\n",
    "    search_results: str | None\n",
    "    retries: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Define the Graph Nodes\n",
    "\n",
    "Nodes are the fundamental building blocks of a LangGraph workflow. Each node is a simple Python function that receives the current `state` and returns a dictionary containing the values to update in the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node 1: `initial_search_node`\n",
    "This node performs the first web search based on the initial topic and initializes our retry counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_search_node(state: AgentState):\n",
    "    print(\"---NODE: Initial Search---\")\n",
    "    search_results = search_tool.run(state['topic'])\n",
    "    return {\"search_results\": search_results, \"retries\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node 2: `analyze_results_node` (Improved Logic)\n",
    "\n",
    "This node uses the LLM to act as a judge. **This is the improved version.** It now explicitly checks if the search tool failed. If so, it immediately decides the results are `insufficient`, making the agent more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def analyze_results_node(state: AgentState):\n",
    "    print(\"---NODE: Analyze Results---\")\n",
    "    search_results = state['search_results']\n",
    "    \n",
    "    # Check for a failed search result explicitly.\n",
    "    if not search_results or \"No good DuckDuckGo Search Result was found\" in search_results:\n",
    "        print(\"Analysis Decision: Search failed, results are insufficient.\")\n",
    "        return {\"messages\": [SystemMessage(content=\"Analysis: insufficient\")]}\n",
    "\n",
    "    analysis_prompt = f\"\"\"You are an expert researcher. Analyze these search results for the topic '{state['topic']}' and determine if they are sufficient to write a comprehensive answer. Respond with only 'sufficient' or 'insufficient'.\\n\\nResults:\\n{state['search_results']}\"\"\"\n",
    "    response = llm.invoke(analysis_prompt)\n",
    "    decision = response.content.strip().lower()\n",
    "    print(f\"Analysis Decision: {decision}\")\n",
    "    return {\"messages\": [SystemMessage(content=f\"Analysis: {decision}\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node 3: `rewrite_query_node`\n",
    "\n",
    "This node is only called if the analysis fails. It uses the LLM to generate a *better* search query and then executes the search again, updating the state with the new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query_node(state: AgentState):\n",
    "    print(\"---NODE: Rewrite Query---\")\n",
    "    retries = state['retries']\n",
    "    rewrite_prompt = f\"\"\"You are a search expert. Your search for '{state['topic']}' was insufficient. Rewrite it into a better, more specific search query.\"\"\"\n",
    "    new_query = llm.invoke(rewrite_prompt).content.strip()\n",
    "    print(f\"New Query: {new_query}\")\n",
    "    search_results = search_tool.run(new_query)\n",
    "    return {\"search_results\": search_results, \"retries\": retries + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node 4: `final_response_node`\n",
    "\n",
    "This is the final step, only reached when the results are deemed sufficient. It synthesizes all the gathered information into a comprehensive answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_response_node(state: AgentState):\n",
    "    print(\"---NODE: Final Response---\")\n",
    "    response_prompt = f\"\"\"Based on the following search results, provide a detailed answer to the topic: '{state['topic']}'.\\n\\nResults:\\n{state['search_results']}\"\"\"\n",
    "    final_response = llm.invoke(response_prompt).content\n",
    "    return {\"messages\": [SystemMessage(content=final_response)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Define the Edges and Assemble the Graph\n",
    "\n",
    "Edges connect our nodes. A **conditional edge** is a special type of edge that uses a function to decide which node to go to next based on the current state. This is how we create our self-correction loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# This function is our conditional edge.\n",
    "def should_continue_edge(state: AgentState):\n",
    "    # First, check for the max retries condition to prevent infinite loops\n",
    "    if state['retries'] > 2:\n",
    "        print(\"---DECISION: Max retries reached, ending.---\")\n",
    "        return \"end\"\n",
    "    \n",
    "    # Check the analysis message in the state\n",
    "    last_message = state['messages'][-1].content\n",
    "    if \"insufficient\" in last_message:\n",
    "        print(\"---DECISION: Results are insufficient, rewriting query.---\")\n",
    "        return \"rewrite\"\n",
    "    else:\n",
    "        print(\"---DECISION: Results are sufficient, generating final response.---\")\n",
    "        return \"end\"\n",
    "\n",
    "# Assemble the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"initial_search\", initial_search_node)\n",
    "workflow.add_node(\"analyze_results\", analyze_results_node)\n",
    "workflow.add_node(\"rewrite_query\", rewrite_query_node)\n",
    "workflow.add_node(\"final_response\", final_response_node)\n",
    "\n",
    "workflow.set_entry_point(\"initial_search\")\n",
    "workflow.add_edge(\"initial_search\", \"analyze_results\")\n",
    "workflow.add_edge(\"rewrite_query\", \"analyze_results\") # The crucial loop!\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_results\",\n",
    "    should_continue_edge,\n",
    "    {\"rewrite\": \"rewrite_query\", \"end\": \"final_response\"} # This dictionary maps the edge function's return value to a node name\n",
    ")\n",
    "workflow.add_edge(\"final_response\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"Graph compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Visualize the Graph\n",
    "\n",
    "One of the best features of LangGraph is the ability to visualize your agent's structure. This makes it incredibly easy to understand and debug the flow.\n",
    "\n",
    "**Note:** This requires `graphviz` and its development libraries to be installed. The command below handles this for Debian-based systems like Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies for visualization\n",
    "!sudo apt-get -qq install -y graphviz libgraphviz-dev\n",
    "!pip install -q pygraphviz\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    # Generate the visualization\n",
    "    graph_image = app.get_graph().draw_mermaid_png()\n",
    "    display(Image(graph_image))\n",
    "except Exception as e:\n",
    "    print(f\"Error generating visualization: {e}\")\n",
    "    print(\"Please ensure graphviz and its development libraries are installed correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5: Run the Graph and Observe the State\n",
    "\n",
    "Now we run our compiled graph. We will `stream` the events to inspect the **interim state** after each node runs. We also pass a `config` dictionary to set a higher recursion limit, preventing the `GraphRecursionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_input = {\"topic\": topic, \"messages\": []}\n",
    "config = {\"recursion_limit\": 50} # Set a higher limit for safety\n",
    "\n",
    "print(\"--- Running LangGraph App ---\")\n",
    "for i, step in enumerate(app.stream(initial_input, config=config)):\n",
    "    # The 'step' object contains the output of the node that just ran\n",
    "    node_name = list(step.keys())[0]\n",
    "    node_output = step[node_name]\n",
    "    \n",
    "    print(f\"\\n--- STEP {i+1}: Executed Node '{node_name}' ---\")\n",
    "    print(\"Output of this node:\")\n",
    "    print(node_output)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Get the final state to print the answer\n",
    "final_state = app.invoke(initial_input, config=config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"          LANGGRAPH FINAL ANSWER\")\n",
    "print(\"=\"*50)\n",
    "display(Markdown(final_state['messages'][-1].content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6: Analysis of the LangGraph Performance\n",
    "\n",
    "As you can see from the output, the flow is explicit and reliable. The graph moves from node to node, the conditional edge correctly routes the flow back for a retry, and the state is updated predictably at each step. This is the power of defining your agent's logic as code rather than as a prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: The Right Tool for the Job\n",
    "\n",
    "- **LangChain `AgentExecutor`:** An excellent tool for rapid prototyping and building agents where the workflow is relatively linear (Tool A -> Tool B -> Answer). It's the \"automatic transmission\" for getting started quickly.\n",
    "\n",
    "- **LangGraph:** The essential tool for building production-grade, reliable agents that require complex, stateful logic. It provides the \"manual transmission\" needed for fine-grained control over cycles, retries, and branching, which is impossible to achieve reliably with a standard agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
